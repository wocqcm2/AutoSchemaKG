{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6b8561",
   "metadata": {},
   "source": [
    "# ATLAS Multihop QA Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee016968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T02:01:01.744497Z",
     "start_time": "2025-07-25T02:01:01.734782Z"
    }
   },
   "source": [
    "# 打印Python版本\n",
    "import sys\n",
    "print(\"Python version:\", sys.version)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.18 (main, Jun  5 2025, 08:37:47) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "4752da40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T02:01:03.267586Z",
     "start_time": "2025-07-25T02:01:03.262752Z"
    }
   },
   "source": [
    "# 设置使用CPU模式\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # 禁用GPU，强制使用CPU\n",
    "import torch\n",
    "print(\"使用设备: CPU\")\n",
    "print(\"CUDA可用:\", torch.cuda.is_available())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: CPU\n",
      "CUDA可用: False\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "bee560d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T02:01:14.488897Z",
     "start_time": "2025-07-25T02:01:05.719437Z"
    }
   },
   "source": [
    "from atlas_rag.vectorstore.embedding_model import SentenceEmbedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 加载SentenceTransformer模型 (CPU版本)\n",
    "encoder_model_name = 'all-MiniLM-L6-v2'\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n",
    "sentence_encoder = SentenceEmbedding(sentence_model)\n",
    "\n",
    "print(f\"使用编码器模型: {encoder_model_name}\")\n",
    "print(f\"模型设备: {sentence_model.device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用编码器模型: all-MiniLM-L6-v2\n",
      "模型设备: cpu\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "9d3d69d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T01:52:23.936394Z",
     "start_time": "2025-07-25T01:52:23.904452Z"
    }
   },
   "source": [
    "# 使用DeepInfra的Meta-Llama模型\n",
    "from openai import OpenAI\n",
    "from atlas_rag.llm_generator import LLMGenerator\n",
    "from configparser import ConfigParser\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# 设置DeepInfra客户端\n",
    "reader_model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"  # 使用与提取时相同的模型\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    "    api_key=config['settings']['DEEPINFRA_API_KEY']\n",
    ")\n",
    "\n",
    "llm_generator = LLMGenerator(client=client, model_name=reader_model_name)\n",
    "print(f\"使用LLM模型: {reader_model_name}\")\n",
    "print(\"API端点: DeepInfra\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用LLM模型: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
      "API端点: DeepInfra\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "aef32633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T02:01:39.433543Z",
     "start_time": "2025-07-25T02:01:39.407814Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "from atlas_rag.llm_generator import LLMGenerator\n",
    "from configparser import ConfigParser\n",
    "# Load OpenRouter API key from config file\n",
    "config = ConfigParser()\n",
    "config.read('config.ini')\n",
    "reader_model_name = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "client = OpenAI(\n",
    "  base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    "  api_key=config['settings']['DEEPINFRA_API_KEY'],\n",
    ")\n",
    "llm_generator = LLMGenerator(client=client, model_name=reader_model_name)\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ae785d41",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-25T02:01:41.024245Z"
    }
   },
   "source": [
    "from atlas_rag.vectorstore import create_embeddings_and_index\n",
    "\n",
    "# 使用与提取时相同的设置\n",
    "keyword = 'musique_sample'  # 使用样本数据集的结果\n",
    "working_directory = './working_data'\n",
    "\n",
    "print(f\"加载数据集: {keyword}\")\n",
    "print(f\"工作目录: {working_directory}\")\n",
    "\n",
    "data = create_embeddings_and_index(\n",
    "    sentence_encoder=sentence_encoder,\n",
    "    model_name=encoder_model_name,\n",
    "    working_directory=working_directory,\n",
    "    keyword=keyword,\n",
    "    include_concept=True,\n",
    "    include_events=True,\n",
    "    normalize_embeddings=True,\n",
    "    text_batch_size=16,  # CPU版本使用较小的batch size\n",
    "    node_and_edge_batch_size=16,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据集: musique_sample\n",
      "工作目录: ./working_data\n",
      "Using encoder model: all-MiniLM-L6-v2\n",
      "Loading graph from ./working_data/kg_graphml/musique_sample_graph.graphml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18717/18717 [00:00<00:00, 2241328.95it/s]\n",
      "100%|██████████| 18717/18717 [00:00<00:00, 2486374.48it/s]\n",
      "87690it [00:00, 5748917.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embeddings already computed.\n",
      "Node and edge embeddings not found, computing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding nodes: 100%|██████████| 1146/1146 [00:21<00:00, 52.36it/s] \n",
      "Encoding edges: 100%|██████████| 4674/4674 [02:11<00:00, 35.46it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "805d5ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T02:05:45.108656Z",
     "start_time": "2025-07-25T02:05:38.909075Z"
    }
   },
   "source": [
    "from atlas_rag.evaluation import BenchMarkConfig\n",
    "benchmark_config = BenchMarkConfig(\n",
    "    dataset_name= 'musique',\n",
    "    question_file= \"benchmark_data/musique.json\",\n",
    "    include_concept=True,\n",
    "    include_events=True,\n",
    "    reader_model_name=reader_model_name,\n",
    "    encoder_model_name=encoder_model_name,\n",
    "    number_of_samples=5, # -1 for all samples\n",
    ")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reader_model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 7\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01matlas_rag\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mevaluation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BenchMarkConfig\n\u001B[1;32m      2\u001B[0m benchmark_config \u001B[38;5;241m=\u001B[39m BenchMarkConfig(\n\u001B[1;32m      3\u001B[0m     dataset_name\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmusique\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      4\u001B[0m     question_file\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbenchmark_data/musique.json\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      5\u001B[0m     include_concept\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      6\u001B[0m     include_events\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m----> 7\u001B[0m     reader_model_name\u001B[38;5;241m=\u001B[39m\u001B[43mreader_model_name\u001B[49m,\n\u001B[1;32m      8\u001B[0m     encoder_model_name\u001B[38;5;241m=\u001B[39mencoder_model_name,\n\u001B[1;32m      9\u001B[0m     number_of_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, \u001B[38;5;66;03m# -1 for all samples\u001B[39;00m\n\u001B[1;32m     10\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'reader_model_name' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a0905b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlas_rag import setup_logger\n",
    "logger = setup_logger(benchmark_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86925bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize desired RAG method for benchmarking\n",
    "from atlas_rag.retriever import HippoRAG2Retriever\n",
    "hipporag2_retriever = HippoRAG2Retriever(\n",
    "    llm_generator=llm_generator,\n",
    "    sentence_encoder=sentence_encoder,\n",
    "    data = data,\n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start benchmarking\n",
    "from atlas_rag.evaluation import RAGBenchmark\n",
    "benchmark = RAGBenchmark(config=benchmark_config, logger=logger)\n",
    "benchmark.run([hipporag2_retriever], llm_generator=llm_generator) \n",
    "# benchmark.run([hipporag2_retriever], llm_generator=llm_generator, use_react=True) # use_react=True to enable RAG with REACT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas-rag-gpu-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
